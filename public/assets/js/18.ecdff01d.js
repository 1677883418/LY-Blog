(window.webpackJsonp=window.webpackJsonp||[]).push([[18],{583:function(t,e,a){"use strict";a.r(e);var s=a(5),r=Object(s.a)({},(function(){var t=this,e=t.$createElement,a=t._self._c||e;return a("ContentSlotsDistributor",{attrs:{"slot-key":t.$parent.slotKey}},[a("h2",{attrs:{id:"shuffle概述"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#shuffle概述"}},[t._v("#")]),t._v(" Shuffle概述")]),t._v(" "),a("h3",{attrs:{id:"mapreduce概述"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#mapreduce概述"}},[t._v("#")]),t._v(" MapReduce概述")]),t._v(" "),a("ul",[a("li",[t._v("阶段:Map、Shuffle、Reduce")])]),t._v(" "),a("h4",{attrs:{id:"map阶段"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#map阶段"}},[t._v("#")]),t._v(" Map阶段")]),t._v(" "),a("p",[t._v("单机上,针对一小块数据的计算过程")]),t._v(" "),a("p",[a("img",{attrs:{src:"https://img.lystu.cn/imgBed/2022/7/31/n5k7qam8i3Map.gif",alt:""}})]),t._v(" "),a("h4",{attrs:{id:"shuffle阶段"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#shuffle阶段"}},[t._v("#")]),t._v(" Shuffle阶段")]),t._v(" "),a("p",[t._v("在map阶段的基础上,进行数据移动,为后续的reduce阶段做准备。\n"),a("img",{attrs:{src:"https://img.lystu.cn/imgBed/2022/7/31/s6b48h1fb3Shuffle.gif",alt:""}})]),t._v(" "),a("h4",{attrs:{id:"reduce阶段"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#reduce阶段"}},[t._v("#")]),t._v(" Reduce阶段")]),t._v(" "),a("p",[t._v("reduce阶段,对移动后的数据进行处理,依然是在单机上处理一小份数据\n"),a("img",{attrs:{src:"https://img.lystu.cn/imgBed/2022/7/31/pdeoiu8c8yReduce.gif",alt:""}})]),t._v(" "),a("h4",{attrs:{id:"shuffle阶段为什么对性能非常重要"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#shuffle阶段为什么对性能非常重要"}},[t._v("#")]),t._v(" Shuffle阶段为什么对性能非常重要")]),t._v(" "),a("ul",[a("li",[t._v("M * R次网络连接")]),t._v(" "),a("li",[t._v("大量的数据移动")]),t._v(" "),a("li",[t._v("数据丢失风险")]),t._v(" "),a("li",[t._v("可能存在大量的排序操作")]),t._v(" "),a("li",[t._v("大量的数据序列化,反序列化操作")]),t._v(" "),a("li",[t._v("数据压缩")])]),t._v(" "),a("h4",{attrs:{id:"小结"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#小结"}},[t._v("#")]),t._v(" 小结")]),t._v(" "),a("p",[t._v("在大数据场景下，数据shuffle表示了"),a("strong",[t._v("不同分区数据交换的过程")]),t._v("，不同的shuffle策略性能差异较大。\n目前在各个引擎中shuffle都是优化的重点，在spark框架中，shuffle是支撑spark进行大规模复杂数据处理的基石。")]),t._v(" "),a("h2",{attrs:{id:"shuffle算子"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#shuffle算子"}},[t._v("#")]),t._v(" Shuffle算子")]),t._v(" "),a("p",[t._v("Spark中会产生shuffle的算子大概分为四类")]),t._v(" "),a("table",[a("thead",[a("tr",[a("th",[t._v("repartition")]),t._v(" "),a("th",[t._v("ByKey")]),t._v(" "),a("th",[t._v("join")]),t._v(" "),a("th",[t._v("Distinct")])])]),t._v(" "),a("tbody",[a("tr",[a("td",[t._v("coalesce")]),t._v(" "),a("td",[t._v("groupByKey")]),t._v(" "),a("td",[t._v("cogroup")]),t._v(" "),a("td",[t._v("distinct")])]),t._v(" "),a("tr",[a("td",[t._v("repartition")]),t._v(" "),a("td",[t._v("reduceByKey")]),t._v(" "),a("td",[t._v("join")]),t._v(" "),a("td")]),t._v(" "),a("tr",[a("td"),t._v(" "),a("td",[t._v("aggregateByKey")]),t._v(" "),a("td",[t._v("leftOuterJoin")]),t._v(" "),a("td")]),t._v(" "),a("tr",[a("td"),t._v(" "),a("td",[t._v("combineByKey")]),t._v(" "),a("td",[t._v("intersection")]),t._v(" "),a("td")]),t._v(" "),a("tr",[a("td"),t._v(" "),a("td",[t._v("sortByKey")]),t._v(" "),a("td",[t._v("subtract")]),t._v(" "),a("td")]),t._v(" "),a("tr",[a("td"),t._v(" "),a("td",[t._v("sortBy")]),t._v(" "),a("td",[t._v("subtractByKey")]),t._v(" "),a("td")])])]),t._v(" "),a("h3",{attrs:{id:"shuffle算子应用"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#shuffle算子应用"}},[t._v("#")]),t._v(" Shuffle算子应用")]),t._v(" "),a("div",{staticClass:"language-scala line-numbers-mode"},[a("pre",{pre:!0,attrs:{class:"language-scala"}},[a("code",[a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("val")]),t._v(" text "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" sc"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("textFile"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('"mytextfile.txt"')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("val")]),t._v(" counts "),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" text\n  "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("flatMap"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("line "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("=>")]),t._v(" line"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("split"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),a("span",{pre:!0,attrs:{class:"token string"}},[t._v('" "')]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n  "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("map"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("word "),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("=>")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("word"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),a("span",{pre:!0,attrs:{class:"token number"}},[t._v("1")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n  "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("reduceByKey"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("_"),a("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),t._v("_"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\ncounts"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("collect\n")])]),t._v(" "),a("div",{staticClass:"line-numbers-wrapper"},[a("span",{staticClass:"line-number"},[t._v("1")]),a("br"),a("span",{staticClass:"line-number"},[t._v("2")]),a("br"),a("span",{staticClass:"line-number"},[t._v("3")]),a("br"),a("span",{staticClass:"line-number"},[t._v("4")]),a("br"),a("span",{staticClass:"line-number"},[t._v("5")]),a("br"),a("span",{staticClass:"line-number"},[t._v("6")]),a("br")])]),a("h3",{attrs:{id:"spark对shuffle的抽象"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#spark对shuffle的抽象"}},[t._v("#")]),t._v(" Spark对Shuffle的抽象")]),t._v(" "),a("ul",[a("li",[t._v("窄依赖：父RDD的每个分片至多被子\nRDD中的一个分片所依赖")]),t._v(" "),a("li",[t._v("宽依赖：父RDD中的分片可能被子\nRDD中的多个分片所依赖")])]),t._v(" "),a("h3",{attrs:{id:"算子内部的依赖关系"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#算子内部的依赖关系"}},[t._v("#")]),t._v(" 算子内部的依赖关系")]),t._v(" "),a("ul",[a("li",[t._v("Shuffle Dependency\n"),a("ul",[a("li",[t._v("创建会产生shuffle的RDD时，RDD会创建Shuffle Dependency来描述Shuffle相关的信息")]),t._v(" "),a("li",[t._v("构造函数\n"),a("ul",[a("li",[t._v("A single key-value pair RDD, i.e. RDD[Product2[K, V]],")]),t._v(" "),a("li",[t._v("Partitioner (available as partitioner property),")]),t._v(" "),a("li",[t._v("Serializer,")]),t._v(" "),a("li",[t._v("Optional key ordering (of Scala’s scala.math.Ordering type),")]),t._v(" "),a("li",[t._v("Optional Aggregator,")]),t._v(" "),a("li",[t._v("mapSideCombine flag which is disabled (i.e. false) by default.")])])])])]),t._v(" "),a("li",[t._v("Partitioner\n"),a("ul",[a("li",[t._v("用来将record映射到具体的partition的方法")]),t._v(" "),a("li",[t._v("接口\n"),a("ul",[a("li",[t._v("numberPartitions")]),t._v(" "),a("li",[t._v("getPartition")])])])])]),t._v(" "),a("li",[t._v("Aggregator\n"),a("ul",[a("li",[t._v("在map侧合并部分record的函数")]),t._v(" "),a("li",[t._v("接口\n"),a("ul",[a("li",[t._v("createCombiner：只有一个value的时候初始化的方法")]),t._v(" "),a("li",[t._v("mergeValue：合并一个value到Aggregator中")]),t._v(" "),a("li",[t._v("mergeCombiners：合并两个Aggregator")])])])])])]),t._v(" "),a("h2",{attrs:{id:"shuffle过程"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#shuffle过程"}},[t._v("#")]),t._v(" Shuffle过程")]),t._v(" "),a("h3",{attrs:{id:"spark中的shuffle变迁过程"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#spark中的shuffle变迁过程"}},[t._v("#")]),t._v(" spark中的shuffle变迁过程")]),t._v(" "),a("ul",[a("li",[t._v("HashShuffle\n"),a("ul",[a("li",[t._v("优点：不需要排序")]),t._v(" "),a("li",[t._v("缺点：打开，创建的文件过多")])])]),t._v(" "),a("li",[t._v("SortShuffle\n"),a("ul",[a("li",[t._v("优点：打开的文件少、支持map-side combine")]),t._v(" "),a("li",[t._v("缺点：需要排序")])])]),t._v(" "),a("li",[t._v("TungstenSortShuffle\n"),a("ul",[a("li",[t._v("优点：更快的排序效率，更高的内存利用效率")]),t._v(" "),a("li",[t._v("缺点：不支持map-side combine")])])])]),t._v(" "),a("h3",{attrs:{id:"register-shuffle"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#register-shuffle"}},[t._v("#")]),t._v(" Register Shuffle")]),t._v(" "),a("ul",[a("li",[t._v("由action算子触发DAG Scheduler进行shuffle register")]),t._v(" "),a("li",[t._v("Shuffle Register会根据不同的条件决定注册不同的ShuffleHandle")])]),t._v(" "),a("h3",{attrs:{id:"shuffle参数优化"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#shuffle参数优化"}},[t._v("#")]),t._v(" Shuffle参数优化")]),t._v(" "),a("ul",[a("li",[t._v("spark.default.parallelism && spark.sql.shuffle.partitions")]),t._v(" "),a("li",[t._v("spark.hadoopRDD.ignoreEmptySplits")]),t._v(" "),a("li",[t._v("spark.hadoop.mapreduce.input.fileinputformat.split.minsize")]),t._v(" "),a("li",[t._v("spark.sql.file.maxPartitionBytes")]),t._v(" "),a("li",[t._v("spark.sql.adaptive.enabled && spark.sql.adaptive.shuffle.targetPostShuffleInputSize")]),t._v(" "),a("li",[t._v("spark.reducer.maxSizeInFlight")]),t._v(" "),a("li",[t._v("spark.reducer.maxReqsInFlight")]),t._v(" "),a("li",[t._v("spark.reducer.maxBlocksInFlightPerAddress")])]),t._v(" "),a("h3",{attrs:{id:"shuffle倾斜优化"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#shuffle倾斜优化"}},[t._v("#")]),t._v(" Shuffle倾斜优化")]),t._v(" "),a("ul",[a("li",[t._v("倾斜影响\n"),a("ul",[a("li",[t._v("作业运行时间变长")]),t._v(" "),a("li",[t._v("Task OOM导致作业失败")])])])]),t._v(" "),a("h4",{attrs:{id:"常见地倾斜处理办法"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#常见地倾斜处理办法"}},[t._v("#")]),t._v(" 常见地倾斜处理办法")]),t._v(" "),a("ul",[a("li",[t._v("提高并行度\n"),a("ul",[a("li",[t._v("优点:足够简单")]),t._v(" "),a("li",[t._v("缺点: 只缓解、不根治")])])]),t._v(" "),a("li",[t._v("AQE Skew Join\n"),a("ul",[a("li",[t._v("AQE根据shuffle文件统计数据自动检测倾斜数据，将那些倾斜的分区打散成小的子分区，然后各自进行join。")])])])]),t._v(" "),a("h2",{attrs:{id:"push-shuffle"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#push-shuffle"}},[t._v("#")]),t._v(" Push Shuffle")]),t._v(" "),a("ul",[a("li",[t._v("上一部分所讲的shuffle过程存在哪些问题？\n"),a("ul",[a("li",[t._v("数据存储在本地磁盘，没有备份")]),t._v(" "),a("li",[t._v("IO 并发：大量 RPC 请求（M*R）")]),t._v(" "),a("li",[t._v("IO 吞吐：随机读、写放大（3X）")]),t._v(" "),a("li",[t._v("GC 频繁，影响 NodeManager")])])]),t._v(" "),a("li",[t._v("为了优化该问题，有很多公司都做了思路相近地优化，push shuffle\n"),a("ul",[a("li",[t._v("Facebook： "),a("a",{attrs:{href:"https://link.juejin.cn?target=https%3A%2F%2Fdatabricks.com%2Fsession%2Fcosco-an-efficient-facebook-scale-shuffle-service",title:"https://databricks.com/session/cosco-an-efficient-facebook-scale-shuffle-service",target:"_blank",rel:"noopener noreferrer"}},[t._v("cosco"),a("OutboundLink")],1)]),t._v(" "),a("li",[t._v("LinkedIn："),a("a",{attrs:{href:"https://link.juejin.cn?target=https%3A%2F%2Fengineering.linkedin.com%2Fblog%2F2020%2Fintroducing-magnet",title:"https://engineering.linkedin.com/blog/2020/introducing-magnet",target:"_blank",rel:"noopener noreferrer"}},[t._v("magnet"),a("OutboundLink")],1)]),t._v(" "),a("li",[t._v("Uber："),a("a",{attrs:{href:"https://link.juejin.cn?target=https%3A%2F%2Fgithub.com%2Fuber%2FRemoteShuffleService",title:"https://github.com/uber/RemoteShuffleService",target:"_blank",rel:"noopener noreferrer"}},[t._v("Zeus"),a("OutboundLink")],1)]),t._v(" "),a("li",[t._v("Alibaba： "),a("a",{attrs:{href:"https://link.juejin.cn?target=https%3A%2F%2Fgithub.com%2Falibaba%2FRemoteShuffleService",title:"https://github.com/alibaba/RemoteShuffleService",target:"_blank",rel:"noopener noreferrer"}},[t._v("RSS"),a("OutboundLink")],1)]),t._v(" "),a("li",[t._v("Tencent： "),a("a",{attrs:{href:"https://link.juejin.cn?target=https%3A%2F%2Fgithub.com%2FTencent%2FFirestorm",title:"https://github.com/Tencent/Firestorm",target:"_blank",rel:"noopener noreferrer"}},[t._v("FireStorm"),a("OutboundLink")],1)]),t._v(" "),a("li",[t._v("Bytedance： Cloud Shuffle Service")]),t._v(" "),a("li",[t._v("Spark3.2： "),a("a",{attrs:{href:"https://link.juejin.cn?target=https%3A%2F%2Fissues.apache.org%2Fjira%2Fbrowse%2FSPARK-30602",title:"https://issues.apache.org/jira/browse/SPARK-30602",target:"_blank",rel:"noopener noreferrer"}},[t._v("push based shuffle"),a("OutboundLink")],1)])])]),t._v(" "),a("li",[t._v("Magnet主要流程\n主要为边写边push的模式，在原有的shuffle基础上尝试push聚合数据，但并不强制完成，读取时优先读取push聚合的结果，对于没有来得及完成聚合或者聚合失败的情况，则fallback到原模式。")])]),t._v(" "),a("p",[t._v("参考:\n"),a("a",{attrs:{href:"https://juejin.cn/post/7123908203590451207/#heading-51",target:"_blank",rel:"noopener noreferrer"}},[t._v("【大数据专场 学习资料二】第四届字节跳动青训营"),a("OutboundLink")],1)])])}),[],!1,null,null,null);e.default=r.exports}}]);